{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mena_std_calculation.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEIgPxPeRzGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/data.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik8PBO59P3ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAj7jOhRlnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='/content/data/fg_bg',\n",
        "                                           transform = torchvision.transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2048,\n",
        "    num_workers=4,\n",
        "    shuffle=False,\n",
        "    pin_memory= True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjcTBTiBQuTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a2159d73-97e5-4279-b7de-4b541325de09"
      },
      "source": [
        "mean = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing mean\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Since the denominator (224*224) is constant, instead of doing sum first and\n",
        "    # then taking mean, we can directly take mean and sum it.\n",
        "    mean += data.mean(2).sum(0)\n",
        "\n",
        "mean /= len(loader.dataset)\n",
        "print(\"\\nMean: \", mean)\n",
        "\n",
        "std = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing std\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Sum (x-mean)^2 per channel across all batches pixels\n",
        "    std += ((data - mean.unsqueeze(1))**2).sum([0,2])\n",
        "\n",
        "std = torch.sqrt(std / (len(loader.dataset)*224*224))\n",
        "print(\"\\nStd: \", std)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing mean: 100%|██████████| 196/196 [16:10<00:00,  4.95s/it]\n",
            "Computing std:   0%|          | 0/196 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean:  tensor([0.5057, 0.4966, 0.4812])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing std: 100%|██████████| 196/196 [18:29<00:00,  5.66s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Std:  tensor([0.2494, 0.2498, 0.2612])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuJAZ_PasxpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='/content/data/fg_bg_mask',\n",
        "                                           transform = torchvision.transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2048,\n",
        "    num_workers=4,\n",
        "    shuffle=False,\n",
        "    pin_memory= True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHP3fXIJsk-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9e035784-38ff-48e8-a2e0-71980bf6a3ca"
      },
      "source": [
        "mean = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing mean\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data[:, 0:1, :, :]#.to(device='cuda')\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Since the denominator (224*224) is constant, instead of doing sum first and\n",
        "    # then taking mean, we can directly take mean and sum it.\n",
        "    mean += data.mean(2).sum(0)\n",
        "\n",
        "mean /= len(loader.dataset)\n",
        "print(\"\\nMean: \", mean)\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "std = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing std\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data[:, 0:1, :, :]#.to(device='cuda')\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Sum (x-mean)^2 per channel across all batches pixels\n",
        "    std += ((data - mean.unsqueeze(1))**2).sum([0,2])\n",
        "\n",
        "std = torch.sqrt(std / (len(loader.dataset)*224*224))\n",
        "print(\"\\nStd: \", std)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing mean: 100%|██████████| 196/196 [11:59<00:00,  3.67s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean:  tensor([0.0498])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing std: 100%|██████████| 196/196 [13:38<00:00,  4.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Std:  tensor([0.2154])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mheCQnBtvMbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/dataset.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2XzRnrNvRRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='/content/dataset/bg',\n",
        "                                           transform = torchvision.transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=100,\n",
        "    num_workers=4,\n",
        "    shuffle=False,\n",
        "    pin_memory= True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvBNgXpMvhi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6e546e93-d043-4bf2-8052-fafa31d7c968"
      },
      "source": [
        "mean = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing mean\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Since the denominator (224*224) is constant, instead of doing sum first and\n",
        "    # then taking mean, we can directly take mean and sum it.\n",
        "    mean += data.mean(2).sum(0)\n",
        "\n",
        "mean /= len(loader.dataset)\n",
        "print(\"\\nMean: \", mean)\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "std = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing std\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Sum (x-mean)^2 per channel across all batches pixels\n",
        "    std += ((data - mean.unsqueeze(1))**2).sum([0,2])\n",
        "\n",
        "std = torch.sqrt(std / (len(loader.dataset)*224*224))\n",
        "print(\"\\nStd: \", std)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing mean: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean:  tensor([0.5039, 0.5001, 0.4849])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing std: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Std:  tensor([0.2465, 0.2463, 0.2582])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS0JUi9XyaQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/fg_bg_depth.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7s-sOvCzUIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='/content/fg_bg_depth',\n",
        "                                           transform = torchvision.transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2048,\n",
        "    num_workers=4,\n",
        "    shuffle=False,\n",
        "    pin_memory= True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7QJD0HJzyJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "664d7b26-bbba-48e4-ba56-1a23a70c178b"
      },
      "source": [
        "mean = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing mean\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data[:, 0:1, :, :].to(device='cuda')\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Since the denominator (224*224) is constant, instead of doing sum first and\n",
        "    # then taking mean, we can directly take mean and sum it.\n",
        "    mean += data.mean(2).sum(0)\n",
        "    torch.cuda.empty_cache() \n",
        "\n",
        "mean /= len(loader.dataset)\n",
        "print(\"\\nMean: \", mean)\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "std = 0.0\n",
        "for data, _ in tqdm(loader, desc=\"Computing std\"):\n",
        "    batch_samples = data.size(0)\n",
        "    # Flatten each channel\n",
        "    data = data[:, 0:1, :, :].to(device='cuda')\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    # Sum (x-mean)^2 per channel across all batches pixels\n",
        "    std += ((data - mean.unsqueeze(1))**2).sum([0,2])\n",
        "    torch.cuda.empty_cache() \n",
        "\n",
        "std = torch.sqrt(std / (len(loader.dataset)*224*224))\n",
        "print(\"\\nStd: \", std)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing mean: 100%|██████████| 196/196 [10:21<00:00,  3.17s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean:  tensor([0.4373], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing std: 100%|██████████| 196/196 [08:29<00:00,  2.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Std:  tensor([0.2728], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}